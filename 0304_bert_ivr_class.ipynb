{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0304_bert_ivr_class.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CV7daXtoeCdV",
        "nvJ4DjDleNO7",
        "OLrj1LLMftSP",
        "CI_IS5T6fv_J"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPpDvgCwKd20G3pBZATuQzP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcwanglucky/filetransfer/blob/master/0304_bert_ivr_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9xhZ6UjTXR2",
        "colab_type": "text"
      },
      "source": [
        "### Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtuRsqxOgNG9",
        "colab_type": "code",
        "outputId": "be6f13dd-f4b5-42f2-d2bf-973df57980c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\r\u001b[K     |▋                               | 10kB 22.9MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 4.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 81kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 102kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 112kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 122kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 133kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 143kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 153kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 163kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 174kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 184kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 194kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 204kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 215kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 225kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 235kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 245kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 256kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 266kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 276kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 286kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 296kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 307kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 317kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 327kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 337kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 348kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 358kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 368kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 378kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 389kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 399kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 409kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 419kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 430kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 440kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 450kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 460kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 471kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 481kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 491kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 501kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\r\u001b[K     |▍                               | 10kB 32.5MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 38.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 46.5MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 52.1MB/s eta 0:00:01\r\u001b[K     |██                              | 51kB 53.3MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61kB 57.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71kB 61.1MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 63.5MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92kB 66.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 102kB 69.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 112kB 69.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 122kB 69.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 133kB 69.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 143kB 69.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 153kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 163kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 174kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 184kB 69.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 194kB 69.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 204kB 69.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 215kB 69.3MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 225kB 69.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 235kB 69.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 245kB 69.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 256kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 266kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 276kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 286kB 69.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 296kB 69.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 307kB 69.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 317kB 69.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 327kB 69.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 337kB 69.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 348kB 69.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 358kB 69.3MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 368kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 378kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 389kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 399kB 69.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 409kB 69.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 419kB 69.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 430kB 69.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 440kB 69.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 450kB 69.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 460kB 69.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 471kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 481kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 491kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 501kB 69.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 512kB 69.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 522kB 69.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 532kB 69.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 542kB 69.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 552kB 69.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 563kB 69.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 573kB 69.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 583kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 593kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 604kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 614kB 69.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 624kB 69.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 634kB 69.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 645kB 69.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 655kB 69.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 665kB 69.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 675kB 69.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 686kB 69.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 696kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 706kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 716kB 69.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 727kB 69.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 737kB 69.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 747kB 69.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 757kB 69.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 768kB 69.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 778kB 69.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 788kB 69.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 798kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 808kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 819kB 69.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 829kB 69.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 839kB 69.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 849kB 69.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 860kB 69.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 870kB 69.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 42.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 54.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=29ce542a85ef16fb6c781b8ab7b320d7cec3425fd95488709a1a3ff781e1220d\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liHXnQDCgTfl",
        "colab_type": "code",
        "outputId": "0bf9b755-36d0-4bfa-d7a0-1b94dcd213e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1ND2yjAMtuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU6NipGHEXWT",
        "colab_type": "text"
      },
      "source": [
        "### Read mapping (15 groups version)\n",
        "根據客服的分類系統將小i的資料分成相對應的15類，並讀入"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYX8ucFGMxn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mapping_15 = pd.read_excel(\"0303分類對照.xlsx\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erV4BkGQNfd9",
        "colab_type": "code",
        "outputId": "718221a4-6ba0-416f-aacf-1eae196f4ea1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "mapping_15.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>小i_index</th>\n",
              "      <th>小i_intent</th>\n",
              "      <th>ivr_index</th>\n",
              "      <th>Note</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>H239_How_KnowAffordHouse</td>\n",
              "      <td>2-4-1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>H146_If_Apply_DecreaseRate</td>\n",
              "      <td>2-4-1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>F46_Why_BuyForeignCur</td>\n",
              "      <td>2-0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>C條碼</td>\n",
              "      <td>1-1-1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>H161_If_TransferLoan_UnpaidLoan</td>\n",
              "      <td>2-4-1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   小i_index                        小i_intent ivr_index Note\n",
              "0         1         H239_How_KnowAffordHouse     2-4-1  NaN\n",
              "1         2       H146_If_Apply_DecreaseRate     2-4-1  NaN\n",
              "2         3            F46_Why_BuyForeignCur       2-0  NaN\n",
              "3         4                              C條碼     1-1-1  NaN\n",
              "4         5  H161_If_TransferLoan_UnpaidLoan     2-4-1  NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1YX8Ph-O4rC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx_list = mapping_15[\"ivr_index\"].value_counts().index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qij1dgrPnM9",
        "colab_type": "code",
        "outputId": "6eba96e4-3c83-4922-f52f-613697e03a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#將ivr的分類從0標起\n",
        "ivr2contclass = {idx: i for i, idx in enumerate(idx_list)}\n",
        "print(ivr2contclass)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'2-4-1': 0, '2-0': 1, '1-4': 2, '2-4-2': 3, '1-1-1': 4, '1-2-1': 5, '1-3-1': 6, '1-1-5': 7, '3-1': 8, '1-5-2': 9, '1-3-5': 10, '1-5-1': 11, '1-3-3': 12, '2-1-8': 13, '1-1-2': 14}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I324OP6pQgW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#讀取原始intent.csv資料\n",
        "df_data = pd.read_csv(\"intent.csv\")\n",
        "# 只留取index及question coluumn\n",
        "df_data = df_data.iloc[:, [0, 2]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkjClsu8SA4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = mapping_15.loc[:, ['小i_index']].to_numpy().squeeze()\n",
        "ivr = mapping_15.loc[:, ['ivr_index']].to_numpy().squeeze()\n",
        "\n",
        "# i2ivr存取一個從小i類別對應到ivr類別的dictionary\n",
        "i2ivr = {i[idx]: ivr[idx] for idx in range(len(i))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGS_QBXjVkjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 若小i的第x類在ivr分類中有相對應的分類就回傳此分類\n",
        "# 否則回傳0\n",
        "def geti2ivr(x):\n",
        "    if x in i2ivr:\n",
        "        return i2ivr[x]\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODWHQAyPbA1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_newclass[\"index\"] = df_data[\"index\"].apply(geti2ivr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrJ-XWwUYixq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_newclass.to_csv(\"0303_intent_newclass/ivrclass.csv\", index = False)\n",
        "#df_newclass.read_csv(\"0303_intent_newclass/ivrclass.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHlnHtw7XMqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 只留下有對照分類的data\n",
        "df_newclass = df_newclass[df_newclass['index'] != 0 ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PSkU73EbOPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 將ivr分類變成連續的\n",
        "def getivr2contclass(x):\n",
        "    return ivr2contclass[x]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blHwSoXpbGyU",
        "colab_type": "code",
        "outputId": "e6b00b34-2969-4919-adaa-830556cbd2d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df_newclass[\"index\"] = df_newclass[\"index\"].apply(getivr2contclass)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC7WJqLliuMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_newclass.to_csv(\"0303_intent_newclass/ivrclasswithmapping.csv\", index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftuCE-8mbJmd",
        "colab_type": "code",
        "outputId": "dc3769c2-2958-45ea-c1f1-fa6a00fe734d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"能被分到15類的資料共有　\", len(df_newclass[\"index\"]), \"　筆\" )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "能被分到15類的資料共有　 2338 　筆\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l4Ku06bFgzX",
        "colab_type": "text"
      },
      "source": [
        "### Read extra mapping (+8 groups)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNwNNDt_FgO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sheet 1包含無法被歸類在原本ivr分類的資料，再額外將這些資料分成８個小組\n",
        "mapping_extra = pd.read_excel(\"0303分類對照.xlsx\", sheet_name = 1 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWzw06k9GqGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m_15 = mapping_15.loc[:, ['小i_index', 'ivr_index']]\n",
        "m_15 = m_15.rename(columns={\"ivr_index\": \"大分類\"})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpGE631pR5v6",
        "colab_type": "code",
        "outputId": "cc2f5306-6127-4f04-df9a-ea02d4679d4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "m_15"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>小i_index</th>\n",
              "      <th>大分類</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2-4-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2-4-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2-0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1-1-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2-4-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>502</td>\n",
              "      <td>2-4-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>503</td>\n",
              "      <td>2-4-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>504</td>\n",
              "      <td>2-4-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>506</td>\n",
              "      <td>2-4-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>507</td>\n",
              "      <td>1-4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>253 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     小i_index    大分類\n",
              "0           1  2-4-1\n",
              "1           2  2-4-1\n",
              "2           3    2-0\n",
              "3           4  1-1-1\n",
              "4           5  2-4-1\n",
              "..        ...    ...\n",
              "248       502  2-4-1\n",
              "249       503  2-4-1\n",
              "250       504  2-4-2\n",
              "251       506  2-4-1\n",
              "252       507    1-4\n",
              "\n",
              "[253 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ3VMoWERzMv",
        "colab_type": "code",
        "outputId": "48b00889-ab78-49cd-9b53-2b2e289def4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "mapping_extra"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>小i_index</th>\n",
              "      <th>小i_intent</th>\n",
              "      <th>Note</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>H225_What_SandHouse</td>\n",
              "      <td>海砂屋</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11</td>\n",
              "      <td>F61_If_CancelGlobalPassTranx</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>G06_GoodWords</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14</td>\n",
              "      <td>H250_How_KnowBuyExpensive</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15</td>\n",
              "      <td>C242_A_Howtoverifycard</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>494</td>\n",
              "      <td>H222_What_Attention_HouseSelfLive</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>496</td>\n",
              "      <td>G10_Roughly</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>500</td>\n",
              "      <td>F171_HowWithdrawForeignCash</td>\n",
              "      <td>外幣提款</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>501</td>\n",
              "      <td>H218_What_ProCon_BuyNewHouse</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>505</td>\n",
              "      <td>H139_What_Diff_FixVariableInterest</td>\n",
              "      <td>房貸利率</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>246 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     小i_index                           小i_intent  Note\n",
              "0           0                 H225_What_SandHouse   海砂屋\n",
              "1          11        F61_If_CancelGlobalPassTranx   NaN\n",
              "2          12                       G06_GoodWords   NaN\n",
              "3          14           H250_How_KnowBuyExpensive   NaN\n",
              "4          15              C242_A_Howtoverifycard   NaN\n",
              "..        ...                                 ...   ...\n",
              "241       494   H222_What_Attention_HouseSelfLive   NaN\n",
              "242       496                         G10_Roughly   NaN\n",
              "243       500         F171_HowWithdrawForeignCash  外幣提款\n",
              "244       501        H218_What_ProCon_BuyNewHouse   NaN\n",
              "245       505  H139_What_Diff_FixVariableInterest  房貸利率\n",
              "\n",
              "[246 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tZl25MtFssc",
        "colab_type": "code",
        "outputId": "1d7cf764-c2c5-4600-8a8b-3874deae71f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        }
      },
      "source": [
        "m_8 = mapping_extra.loc[:, ['小i_index', '大分類']]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5fb0d70da615>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm_8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping_extra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'小i_index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'大分類'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1287\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1952\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1954\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m             return self.obj._reindex_with_indexers(\n\u001b[1;32m   1597\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m         )\n\u001b[1;32m   1555\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1653\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 1655\u001b[0;31m                     \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1656\u001b[0m                     \u001b[0;34m\"is no longer supported, see \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m                     \u001b[0;34m\"https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"\u001b[0m  \u001b[0;31m# noqa:E501\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlTNVrEmFsqn",
        "colab_type": "code",
        "outputId": "f4976832-732a-4a9d-8e6b-01b7b3296d94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "# 把原先的15類跟額外分的8類合起來\n",
        "m_23 = pd.concat([m_15, m_8])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f27389dfc8ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm_23\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm_15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'm_8' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVHmiwCpFsot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx_list = m_23[\"大分類\"].value_counts().index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bANWTu6vHhxI",
        "colab_type": "code",
        "outputId": "731b9c82-08ce-4f49-a3d9-9ffdbbfdaef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "ivr2contclass = {idx: i for i, idx in enumerate(idx_list)}\n",
        "print(\"將新的23種ivr分類指定連續標籤：\")\n",
        "print(ivr2contclass)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "將新的23種ivr分類指定連續標籤：\n",
            "{'house': 0, '2-4-1': 1, '2-0': 2, '1-4': 3, 'card': 4, 'paypal': 5, 'miscellaneous': 6, 'cheque': 7, '2-4-2': 8, 'trash': 9, '1-1-1': 10, '1-2-1': 11, '1-3-1': 12, '1-1-5': 13, 'info': 14, 'foreign': 15, '2-1-8': 16, '3-1': 17, '1-5-2': 18, '1-3-3': 19, '1-5-1': 20, '1-3-5': 21, '1-1-2': 22}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6JYrPJzH3H9",
        "colab_type": "code",
        "outputId": "ec347aa4-67a1-4d37-9274-7a92f24cf2b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "m_23.dropna(axis=0, how='any', inplace=True)\n",
        "m_23.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>小i_index</th>\n",
              "      <th>大分類</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2-4-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2-4-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2-0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1-1-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2-4-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   小i_index    大分類\n",
              "0         1  2-4-1\n",
              "1         2  2-4-1\n",
              "2         3    2-0\n",
              "3         4  1-1-1\n",
              "4         5  2-4-1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwMw1HZ_IoqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"intent.csv\")\n",
        "# 只留取index及question coluumn\n",
        "df_data = df.iloc[:, [0, 2]]\n",
        "df_class = df.iloc[:, [0, 1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QMtLwkQHh1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = m_23.loc[:, ['小i_index']].to_numpy().squeeze()\n",
        "ivr = m_23.loc[:, ['大分類']].to_numpy().squeeze()\n",
        "i2ivr = {i[idx]: ivr[idx] for idx in range(len(i))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8moPv6MGHh4A",
        "colab_type": "code",
        "outputId": "a0e9d565-4c87-4394-e04e-66b8f22ca0e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(\"小i分類對應到新的23種ivr分類的對照表：\")\n",
        "print(i2ivr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "小i分類對應到新的23種ivr分類的對照表：\n",
            "{1: '2-4-1', 2: '2-4-1', 3: '2-0', 4: '1-1-1', 5: '2-4-1', 6: '1-3-1', 7: '2-4-2', 8: '2-4-1', 9: '2-0', 10: '1-4', 13: '1-4', 16: '2-4-1', 17: '2-4-1', 19: '1-2-1', 20: '2-4-1', 21: '2-0', 22: '1-4', 23: '2-4-1', 25: '2-0', 27: '2-4-1', 30: '2-4-1', 31: '2-4-1', 33: '2-0', 34: '2-4-1', 35: '1-4', 36: '2-4-1', 37: '2-4-1', 39: '2-4-1', 40: '1-3-5', 41: '1-3-3', 43: '2-4-1', 44: '1-2-1', 49: '2-4-1', 50: '1-4', 55: '2-4-1', 57: '2-0', 59: '3-1', 64: '2-4-1', 73: '2-0', 79: '2-0', 80: '2-0', 82: '1-1-2', 83: '2-4-1', 85: '2-0', 88: '1-4', 89: '2-0', 90: '2-4-1', 91: '2-0', 92: '2-0', 94: '2-0', 95: '2-1-8', 96: '2-0', 97: '2-4-1', 98: '2-4-1', 100: '1-4', 101: '2-0', 102: '1-4', 104: '2-4-1', 105: '2-4-1', 107: '1-4', 109: '2-4-1', 113: '2-4-1', 114: '2-4-1', 117: '2-0', 118: '2-0', 119: '2-0', 120: '2-0', 121: '2-4-1', 122: '2-4-1', 124: '2-4-1', 127: '2-4-1', 129: '1-1-1', 130: '1-4', 131: '2-0', 132: '2-0', 133: '2-0', 134: '2-0', 135: '2-4-2', 137: '2-4-1', 139: '2-0', 140: '2-0', 150: '2-4-2', 151: '2-4-1', 154: '1-4', 155: '2-0', 158: '2-4-1', 162: '2-0', 163: '2-4-1', 164: '1-4', 165: '2-4-1', 167: '2-4-1', 175: '2-0', 176: '2-4-1', 177: '2-0', 178: '2-0', 180: '2-0', 181: '2-4-1', 185: '2-0', 186: '2-0', 187: '2-4-1', 188: '2-4-1', 190: '2-4-1', 192: '1-4', 193: '2-4-1', 196: '2-4-1', 197: '2-4-1', 204: '1-1-1', 210: '2-4-1', 213: '2-0', 214: '1-4', 215: '2-0', 216: '2-4-1', 217: '2-0', 219: '2-0', 221: '2-0', 222: '2-4-1', 223: '1-4', 227: '2-0', 232: '2-4-1', 236: '1-4', 239: '2-0', 241: '2-4-1', 246: '2-4-1', 247: '2-4-1', 248: '2-4-1', 251: '1-4', 252: '1-4', 253: '1-4', 254: '2-4-1', 255: '2-4-1', 259: '1-4', 260: '2-4-1', 261: '2-0', 264: '2-0', 267: '2-4-1', 272: '2-4-1', 275: '2-4-1', 276: '2-4-1', 281: '2-4-1', 282: '2-4-1', 283: '2-0', 284: '2-4-1', 291: '2-0', 294: '2-4-1', 297: '2-4-1', 299: '2-0', 300: '2-4-1', 302: '2-0', 308: '2-4-1', 309: '2-0', 310: '1-4', 311: '2-4-1', 313: '2-0', 315: 'house', 316: '1-4', 319: '2-0', 320: '2-0', 321: '2-0', 323: '2-4-1', 328: '2-4-1', 330: '2-4-1', 332: '2-4-1', 333: '2-4-1', 335: '2-0', 336: '2-4-1', 337: '2-4-1', 338: '1-4', 339: '2-4-1', 340: '2-0', 342: '2-4-1', 344: '2-0', 347: '2-0', 348: '2-4-1', 351: '2-0', 357: '2-0', 358: '2-4-2', 361: '2-4-1', 362: '2-0', 363: '1-4', 364: '2-4-1', 366: '2-4-1', 369: '1-5-1', 370: '2-4-1', 371: '2-0', 373: '2-0', 378: '1-4', 379: '2-0', 380: '2-0', 381: '2-0', 382: '2-4-1', 386: '2-4-1', 387: '2-4-1', 389: '2-4-1', 395: '1-5-2', 396: '2-4-1', 398: '2-0', 399: '2-4-1', 403: '2-4-1', 405: '1-1-5', 407: '2-4-2', 408: '2-0', 410: '1-1-1', 412: '2-4-1', 413: '2-0', 414: '2-4-1', 415: '1-4', 416: '1-1-5', 419: '2-4-2', 420: '2-0', 426: '1-2-1', 427: '2-0', 429: '1-4', 431: '2-4-1', 432: '2-4-1', 433: '2-4-1', 434: '1-3-1', 436: '1-4', 439: '2-4-1', 441: '2-4-1', 443: '2-4-1', 444: '2-0', 446: '1-4', 447: '2-0', 448: '1-1-5', 449: '2-0', 451: '1-4', 453: '2-4-1', 456: '2-0', 460: '2-0', 462: '2-4-1', 464: '2-0', 468: '2-4-2', 471: '2-4-1', 475: '2-4-2', 476: '2-0', 477: '2-0', 479: '2-4-1', 481: '2-4-1', 482: '2-4-1', 485: '2-4-1', 486: '2-0', 489: '2-0', 490: '2-4-1', 493: '1-4', 495: '2-0', 497: '1-3-1', 498: '2-4-1', 499: '2-0', 502: '2-4-1', 503: '2-4-1', 504: '2-4-2', 506: '2-4-1', 507: '1-4', 0: 'house', 11: 'miscellaneous', 12: 'trash', 14: 'house', 15: 'card', 18: 'house', 24: 'card', 26: 'miscellaneous', 28: 'house', 29: 'house', 32: 'house', 38: 'house', 42: 'house', 45: 'card', 46: 'house', 48: 'house', 51: 'house', 52: 'house', 53: 'cheque', 54: 'cheque', 56: 'trash', 58: 'house', 60: 'card', 61: 'house', 62: 'cheque', 63: 'house', 65: 'house', 66: 'miscellaneous', 67: 'miscellaneous', 68: 'house', 69: 'house', 70: 'card', 71: 'house', 72: 'house', 74: 'card', 75: 'miscellaneous', 76: 'house', 77: 'card', 81: 'paypal', 84: 'house', 86: 'house', 87: 'miscellaneous', 93: 'card', 99: 'house', 103: 'card', 106: 'house', 108: 'house', 115: 'house', 116: 'house', 123: 'house', 126: 'house', 128: 'miscellaneous', 136: 'house', 138: 'house', 141: 'card', 142: 'house', 143: 'house', 144: 'house', 145: 'paypal', 146: 'card', 147: 'foreign', 152: 'house', 153: 'house', 159: 'paypal', 161: 'house', 166: 'house', 168: 'house', 169: 'paypal', 170: 'cheque', 171: 'house', 172: 'paypal', 173: 'house', 174: 'house', 183: 'house', 184: 'house', 189: 'house', 191: 'paypal', 194: 'house', 195: 'card', 198: 'paypal', 199: 'house', 200: 'house', 201: 'card', 202: 'house', 203: 'house', 205: 'house', 206: 'card', 207: 'card', 208: 'house', 209: 'card', 211: 'house', 212: 'house', 218: 'cheque', 220: 'cheque', 224: 'house', 225: 'house', 228: 'cheque', 230: 'house', 231: 'house', 233: 'card', 235: 'miscellaneous', 237: 'info', 238: 'house', 242: 'miscellaneous', 243: 'house', 245: 'card', 250: 'paypal', 257: 'house', 258: 'house', 262: 'trash', 263: 'house', 266: 'trash', 268: 'house', 269: 'miscellaneous', 270: 'paypal', 271: 'house', 273: 'house', 274: 'miscellaneous', 278: 'card', 279: 'paypal', 280: 'card', 285: 'house', 286: 'house', 287: 'miscellaneous', 288: 'house', 289: 'miscellaneous', 290: 'house', 292: 'house', 293: 'house', 295: 'paypal', 296: 'house', 298: 'house', 301: 'house', 303: 'paypal', 304: 'card', 305: 'paypal', 307: 'house', 312: 'house', 314: 'house', 317: 'paypal', 318: 'trash', 322: 'house', 324: 'miscellaneous', 325: 'miscellaneous', 326: 'house', 329: 'house', 331: 'cheque', 334: 'card', 341: 'house', 343: 'house', 345: 'info', 346: 'house', 349: 'house', 352: 'card', 353: 'house', 354: 'miscellaneous', 355: 'paypal', 356: 'house', 359: 'cheque', 360: 'house', 365: 'cheque', 367: 'card', 368: 'paypal', 372: 'house', 374: 'house', 376: 'paypal', 377: 'house', 383: 'house', 384: 'house', 385: 'house', 388: 'card', 390: 'card', 391: 'house', 392: 'house', 393: 'house', 394: 'paypal', 397: 'house', 400: 'cheque', 401: 'house', 402: 'house', 404: 'house', 406: 'house', 409: 'house', 411: 'house', 417: 'foreign', 418: 'miscellaneous', 421: 'house', 422: 'house', 423: 'house', 424: 'paypal', 428: 'trash', 430: 'house', 435: 'house', 437: 'house', 438: 'trash', 440: 'miscellaneous', 442: 'house', 450: 'house', 452: 'house', 454: 'house', 457: 'house', 458: 'house', 459: 'house', 461: 'house', 463: 'house', 465: 'card', 466: 'house', 467: 'house', 469: 'house', 470: 'house', 472: 'paypal', 473: 'trash', 474: 'house', 478: 'house', 480: 'house', 483: 'house', 484: 'paypal', 487: 'house', 488: 'card', 492: 'house', 494: 'house', 496: 'trash', 501: 'house', 505: 'house'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhDOv1DsHh7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 若小i的第x類在ivr分類中有相對應的分類就回傳此分類\n",
        "# 否則回傳0\n",
        "def geti2ivr(x):\n",
        "    if x in i2ivr:\n",
        "        return i2ivr[x]\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGQTq_9cIK17",
        "colab_type": "code",
        "outputId": "7cb85957-726b-40a6-f624-658e8f366c70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df_newclass[\"index\"] = df_data[\"index\"].apply(geti2ivr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xa0aGfpLtDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 只留下有對照分類的data\n",
        "df_new = df_newclass[df_newclass['index'] != 0 ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55pspCRBIK5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 將ivr分類變成連續的\n",
        "def getivr2contclass(x):\n",
        "    return ivr2contclass[x]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6jsohO5JIu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_new.dropna(axis=0, how='any', inplace=True)\n",
        "df_new[\"index\"] = df_new[\"index\"].apply(getivr2contclass)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNKSMIJWk4c8",
        "colab_type": "text"
      },
      "source": [
        "### 生成對照表\n",
        "（原本小i的499種分類對應到新的23種ivr分類）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRkvW39eZmat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ivr分類編碼與文字對應\n",
        "ivr2ivrfull = {'1-1-1': '使用網路查詢帳單額度，繳款，補寄電子帳單，申請自動扣繳',\n",
        " '1-1-2': '語音查詢及調整可用額度',\n",
        " '1-1-5': '繳款方式',\n",
        " '1-2-1': '使用網路查詢辦卡進度，開卡',\n",
        " '1-3-1': '卡友貸款專人服務',\n",
        " '1-3-3': '網路申辦預借現金',\n",
        " '1-3-5': '合作廠師付費分期',\n",
        " '1-4': '紅利兌換，機場停車，貴賓室，旅遊保險，市區停車優惠',\n",
        " '1-5-1': '查詢優惠內容',\n",
        " '1-5-2': '網路預約機場接送',\n",
        " '2-0': '外匯及其他服務',\n",
        " '2-1-8': '支存照會',\n",
        " '2-4-1': '貸款申請（轉接專人）',\n",
        " '2-4-2': '查詢貸款當期應繳款日期及金額',\n",
        " '3-1': '使用智能小玉查詢',\n",
        " 'card': 'Other-卡相關',\n",
        " 'cheque': 'Other-旅行支票相關',\n",
        " 'foreign': 'Other-國外旅遊相關',\n",
        " 'house': 'Other-房屋相關',\n",
        " 'info': 'Other-玉山歷史',\n",
        " 'miscellaneous': 'Other-其他雜事（非幹話）',\n",
        " 'paypal': 'Other-Paypal相關',\n",
        " 'trash': 'Other-幹話'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVSLh5pfV6Hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i_class = []\n",
        "ivr_class = []\n",
        "i_intent = []\n",
        "ivr_intent = []\n",
        "\n",
        "for k in sorted(i2ivr):\n",
        "    i_class.append(k)\n",
        "    ivr_class.append(i2ivr[k])\n",
        "    i_intent.append(df_class[df_class['index'] == k]['intent'].iloc[0])\n",
        "    ivr_intent.append(ivr2ivrfull[i2ivr[k]])\n",
        "    #print(k, i2ivr[k], df_class[df_class['index'] == k]['intent'].iloc[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmrNEv9oYJTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_mapping = pd.DataFrame(list(zip(i_class, i_intent, ivr_class, ivr_intent)), columns=['小i_intent', '小i_full_intent', 'ivr_intent', 'ivr_full_intent'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAUG8_VVYJQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_mapping.to_csv(\"mapping_detail.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Phdxie1GnjuB",
        "colab_type": "text"
      },
      "source": [
        "#### df_mapping是小i與ivr分類的對照表 <br>\n",
        "ivr_intent欄位：有編碼的是按照客服分類邏輯分類的結果；若為英文字(ex: house, cheque)，則是將無法分進原本客服分類的資料，依照概略邏輯再加以分類。最後共有23類"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wmkYLESne1h",
        "colab_type": "code",
        "outputId": "57366e82-de0d-4b9f-c7ef-2e8cd6d4aafb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df_mapping"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>小i_intent</th>\n",
              "      <th>小i_full_intent</th>\n",
              "      <th>ivr_intent</th>\n",
              "      <th>ivr_full_intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>H225_What_SandHouse</td>\n",
              "      <td>house</td>\n",
              "      <td>Other-房屋相關</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>H239_How_KnowAffordHouse</td>\n",
              "      <td>2-4-1</td>\n",
              "      <td>貸款申請（轉接專人）</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>H146_If_Apply_DecreaseRate</td>\n",
              "      <td>2-4-1</td>\n",
              "      <td>貸款申請（轉接專人）</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>F46_Why_BuyForeignCur</td>\n",
              "      <td>2-0</td>\n",
              "      <td>外匯及其他服務</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>C條碼</td>\n",
              "      <td>1-1-1</td>\n",
              "      <td>使用網路查詢帳單額度，繳款，補寄電子帳單，申請自動扣繳</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>472</th>\n",
              "      <td>503</td>\n",
              "      <td>H147_What_Factor_AssessLoan</td>\n",
              "      <td>2-4-1</td>\n",
              "      <td>貸款申請（轉接專人）</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>473</th>\n",
              "      <td>504</td>\n",
              "      <td>H133_How_InquiryRemainAmtRate</td>\n",
              "      <td>2-4-2</td>\n",
              "      <td>查詢貸款當期應繳款日期及金額</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>474</th>\n",
              "      <td>505</td>\n",
              "      <td>H139_What_Diff_FixVariableInterest</td>\n",
              "      <td>house</td>\n",
              "      <td>Other-房屋相關</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>475</th>\n",
              "      <td>506</td>\n",
              "      <td>H81_LoanAssess_NoResult</td>\n",
              "      <td>2-4-1</td>\n",
              "      <td>貸款申請（轉接專人）</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>507</td>\n",
              "      <td>C115_EsunWorldCard_DiscountManual</td>\n",
              "      <td>1-4</td>\n",
              "      <td>紅利兌換，機場停車，貴賓室，旅遊保險，市區停車優惠</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>477 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     小i_intent  ...              ivr_full_intent\n",
              "0            0  ...                   Other-房屋相關\n",
              "1            1  ...                   貸款申請（轉接專人）\n",
              "2            2  ...                   貸款申請（轉接專人）\n",
              "3            3  ...                      外匯及其他服務\n",
              "4            4  ...  使用網路查詢帳單額度，繳款，補寄電子帳單，申請自動扣繳\n",
              "..         ...  ...                          ...\n",
              "472        503  ...                   貸款申請（轉接專人）\n",
              "473        504  ...               查詢貸款當期應繳款日期及金額\n",
              "474        505  ...                   Other-房屋相關\n",
              "475        506  ...                   貸款申請（轉接專人）\n",
              "476        507  ...    紅利兌換，機場停車，貴賓室，旅遊保險，市區停車優惠\n",
              "\n",
              "[477 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV7daXtoeCdV",
        "colab_type": "text"
      },
      "source": [
        "### Create split based on percentage (Get every index sampled)\n",
        "邏輯：每種class都取perct %的資料進去training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI7MRUmObJtE",
        "colab_type": "code",
        "outputId": "e9844dc4-879d-442c-cab4-b147d13f4261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "NUM_LABELS = len(df_new['index'].value_counts())\n",
        "print(\"label的數量：{}\".format(NUM_LABELS))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label的數量：23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXCeIwqZd5Ds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 從各類別random sample出fraction比例的資料集\n",
        "    data: df data that includes the \"index\" and \"question\" column\n",
        "    fraction: the fraction of data you want to sample (ex: 0.7)\n",
        "\"\"\" \n",
        "def bootstrap(data, fraction):\n",
        "    # This function will be applied on each group of instances of the same\n",
        "    # class in data.\n",
        "    def sampleClass(classgroup):\n",
        "        return classgroup.sample(frac = fraction)\n",
        "\n",
        "    samples = data.groupby('index').apply(sampleClass)\n",
        "    \n",
        "    # If you want an index which is equal to the row in `data` where the sample came from\n",
        "    # If you don't change it then you'll have a multiindex with level 0\n",
        "    # being the class and level 1 being the row in `data` where\n",
        "    # the sample came from.\n",
        "    samples.index = samples.index.get_level_values(1)\n",
        "    return samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvJ4DjDleNO7",
        "colab_type": "text"
      },
      "source": [
        "### 輸出預處理解果(train and test set)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tMVb_vId5JJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 將原本全部的cleaned data依照指定的比例分成train/val/test set，\n",
        "    並output成tsv檔到環境中(檔名ex: 70%train.tsv)\n",
        "    df: df data that includes the \"index\" and \"question\" column\n",
        "    fraction: fraction of all data to be assigned to training set\n",
        "    The remaining (1-fraction) data will be equally splitted between\n",
        "    validation and testing set\n",
        "\"\"\"\n",
        "\n",
        "def output_split(df, fraction = 0.7):\n",
        "    df_train = bootstrap(df, fraction)\n",
        "    df_remain = pd.concat([df_train, df]).drop_duplicates(keep=False)\n",
        "    df_val = df_remain.sample(frac = 0.5)\n",
        "    df_test = pd.concat([df_val, df_remain]).drop_duplicates(keep=False)\n",
        "\n",
        "    # 放入label資料夾，以區分出之後unlabel的資料\n",
        "    path = os.path.join(\"0303_intent_newclass\", \"data23\")\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "    print(\"訓練樣本數：\", len(df_train))\n",
        "    df_train.to_csv(os.path.join(path, str(int(fraction * 100))+\"%train.tsv\"), index=False)\n",
        "\n",
        "    print(\"validation樣本數：\", len(df_val))\n",
        "    df_val.to_csv(os.path.join(path, str(int(fraction * 100))+\"%val.tsv\"), index=False)\n",
        "\n",
        "    print(\"預測樣本數：\", len(df_test))\n",
        "    df_test.to_csv(os.path.join(path, str(int(fraction * 100))+\"%test.tsv\"), index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThfYH3cdfAul",
        "colab_type": "code",
        "outputId": "a55de218-b111-42bf-f238-c54b80e8e5e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "output_split(df_new, 0.7)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "訓練樣本數： 2985\n",
            "validation樣本數： 636\n",
            "預測樣本數： 635\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLrj1LLMftSP",
        "colab_type": "text"
      },
      "source": [
        "### 讀取前面預處理結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0VPjPhKfMZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = os.path.join(\"0303_intent_newclass\", \"data23\")\n",
        "fraction = 0.7\n",
        "train_path = os.path.join(path, str(int(fraction * 100))+\"%train.tsv\")\n",
        "val_path = os.path.join(path, str(int(fraction * 100))+\"%val.tsv\")\n",
        "test_path = os.path.join(path, str(int(fraction * 100))+\"%test.tsv\")\n",
        "df_train = pd.read_csv(train_path).fillna(\"\")\n",
        "df_val = pd.read_csv(val_path).fillna(\"\")\n",
        "df_test = pd.read_csv(test_path).fillna(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI_IS5T6fv_J",
        "colab_type": "text"
      },
      "source": [
        "### 用OnlineQueryDataset來存取資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ITL3ypgfgiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    實作一個可以用來讀取訓練 / 測試集的 Dataset，此 Dataset 每次將 tsv 裡的一筆成對句子\n",
        "    轉換成 BERT 相容的格式，並回傳 3 個 tensors：\n",
        "    - tokens_tensor：兩個句子合併後的索引序列，包含 [CLS] 與 [SEP]\n",
        "    - segments_tensor：可以用來識別兩個句子界限的 binary tensor\n",
        "    - label_tensor：將分類標籤轉換成類別索引的 tensor, 如果是測試集則回傳 None\n",
        "\"\"\"\n",
        "from torch.utils.data import Dataset\n",
        "   \n",
        "class OnlineQueryDataset(Dataset):\n",
        "    # 讀取前處理後的 tsv 檔並初始化一些參數\n",
        "    # mode: in [\"train\", \"test\", \"val\"]\n",
        "    # tokenizer: one of bert tokenizer\n",
        "    # perc: percentage of data to put in training set\n",
        "    # path: if given, then read data from the path(ex training set)\n",
        "    def __init__(self, mode, tokenizer, perc = 70, path = None):\n",
        "        assert mode in [\"train\", \"val\", \"test\"]  # 一般訓練你會需要 dev set\n",
        "        self.mode = mode\n",
        "        if not path: \n",
        "            path = os.path.join(\"0303_intent_newclass\", \"data23\")\n",
        "            path = os.path.join(path, str(perc) + \"%\" + mode + \".tsv\")\n",
        "        self.df = pd.read_csv(path).fillna(\"\")\n",
        "        self.len = len(self.df)\n",
        "        self.tokenizer = tokenizer \n",
        "    \n",
        "    # 定義回傳一筆訓練 / 測試數據的函式\n",
        "    #@pysnooper.snoop()  # 加入以了解所有轉換過程\n",
        "    def __getitem__(self, idx):\n",
        "        if self.mode == \"test\":\n",
        "            text = self.df.iloc[idx, 1]\n",
        "            label_tensor = None\n",
        "        elif self.mode == \"val\":\n",
        "            label, text = self.df.iloc[idx, :].values\n",
        "            label_tensor = torch.tensor(label)\n",
        "        else:\n",
        "            label, text = self.df.iloc[idx, :].values\n",
        "            # 將label文字也轉換成索引方便轉換成 tensor\n",
        "            label_tensor = torch.tensor(label)\n",
        "            \n",
        "        \"\"\"\n",
        "        # 建立第一個句子的 BERT tokens 並加入分隔符號 [SEP]\n",
        "        word_pieces = [\"[CLS]\"]\n",
        "        tokens_a = self.tokenizer.tokenize(text_a)\n",
        "        word_pieces += tokens_a + [\"[SEP]\"]\n",
        "        len_a = len(word_pieces)\n",
        "        \n",
        "        # 第二個句子的 BERT tokens\n",
        "        tokens_b = self.tokenizer.tokenize(text_b)\n",
        "        word_pieces += tokens_b + [\"[SEP]\"]\n",
        "        len_b = len(word_pieces) - len_a\n",
        "        \"\"\"\n",
        "        # 建立句子的 BERT tokens \n",
        "        word_pieces = [\"[CLS]\"]\n",
        "        tokens = self.tokenizer.tokenize(text)\n",
        "        word_pieces += tokens + [\"[SEP]\"]\n",
        "        len_a = len(word_pieces)\n",
        "        \n",
        "        # 將整個 token 序列轉換成索引序列\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
        "        tokens_tensor = torch.tensor(ids)\n",
        "        \n",
        "        # 將第一句包含 [SEP] 的 token 位置設為 0，其他為 1 表示第二句\n",
        "        segments_tensor = torch.tensor([1] * len_a, dtype=torch.long)\n",
        "        \n",
        "        return (tokens_tensor, segments_tensor, label_tensor)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuoyB9qefrPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
        "# 取得此預訓練模型所使用的 tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSEaMg9ufrSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 初始化一個專門讀取訓練樣本的 Dataset，使用中文 BERT 斷詞\n",
        "trainset = OnlineQueryDataset(\"train\", tokenizer=tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JMPEfxqfrUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valset = OnlineQueryDataset(\"val\", tokenizer=tokenizer)\n",
        "testset = OnlineQueryDataset(\"test\", tokenizer=tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRQlEmsEfgkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "實作可以一次回傳一個 mini-batch 的 DataLoader\n",
        "這個 DataLoader 吃我們上面定義的 `OnlineQueryDataset`，\n",
        "回傳訓練 BERT 時會需要的 4 個 tensors：\n",
        "- tokens_tensors  : (batch_size, max_seq_len_in_batch)\n",
        "- segments_tensors: (batch_size, max_seq_len_in_batch)\n",
        "- masks_tensors   : (batch_size, max_seq_len_in_batch)\n",
        "- label_ids       : (batch_size)\n",
        "\"\"\"\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# 這個函式的輸入 `samples` 是一個 list，裡頭的每個 element 都是\n",
        "# 剛剛定義的 `FakeNewsDataset` 回傳的一個樣本，每個樣本都包含 3 tensors：\n",
        "# - tokens_tensor\n",
        "# - segments_tensor\n",
        "# - label_tensor\n",
        "# 它會對前兩個 tensors 作 zero padding，並產生前面說明過的 masks_tensors\n",
        "def create_mini_batch(samples):\n",
        "    tokens_tensors = [s[0] for s in samples]\n",
        "    segments_tensors = [s[1] for s in samples]\n",
        "    \n",
        "    # 訓練集有 labels\n",
        "    if samples[0][2] is not None:\n",
        "        label_ids = torch.stack([s[2] for s in samples])\n",
        "    else:\n",
        "        label_ids = None\n",
        "    \n",
        "    # zero pad 到同一序列長度\n",
        "    tokens_tensors = pad_sequence(tokens_tensors, \n",
        "                                  batch_first=True)\n",
        "    segments_tensors = pad_sequence(segments_tensors, \n",
        "                                    batch_first=True)\n",
        "    \n",
        "    # attention masks，將 tokens_tensors 裡頭不為 zero padding\n",
        "    # 的位置設為 1 讓 BERT 只關注這些位置的 tokens\n",
        "    masks_tensors = torch.zeros(tokens_tensors.shape, \n",
        "                                dtype=torch.long)\n",
        "    masks_tensors = masks_tensors.masked_fill(\n",
        "        tokens_tensors != 0, 1)\n",
        "    \n",
        "    return tokens_tensors, segments_tensors, masks_tensors, label_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vq-qcZVgluR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 初始化一個每次回傳 64 個訓練樣本的 DataLoader\n",
        "# 利用 `collate_fn` 將 list of samples 合併成一個 mini-batch 是關鍵\n",
        "BATCH_SIZE = 64\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True,  \n",
        "                         collate_fn=create_mini_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNA1Wr8egl2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valloader = DataLoader(valset, batch_size=BATCH_SIZE,  \n",
        "                         collate_fn=create_mini_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6BVpbRigpzs",
        "colab_type": "text"
      },
      "source": [
        "### Training step\n",
        "初始化一個BertForSequenceClassification Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgEgZZP2glsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    PRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GoX8ozRglqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predictions(model, dataloader, compute_acc=False):\n",
        "    predictions = None\n",
        "    correct = 0\n",
        "    total = 0\n",
        "      \n",
        "    with torch.no_grad():\n",
        "        # 遍巡整個資料集\n",
        "        for data in dataloader:\n",
        "            # 將所有 tensors 移到 GPU 上\n",
        "            if next(model.parameters()).is_cuda:\n",
        "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
        "            \n",
        "            # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n",
        "            # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n",
        "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
        "            outputs = model(input_ids=tokens_tensors, \n",
        "                            token_type_ids=segments_tensors, \n",
        "                            attention_mask=masks_tensors)\n",
        "            \n",
        "            logits = outputs[0]\n",
        "            _, pred = torch.max(logits.data, 1)\n",
        "            \n",
        "            # 用來計算訓練集的分類準確率\n",
        "            if compute_acc:\n",
        "                labels = data[3]\n",
        "                total += labels.size(0)\n",
        "                correct += (pred == labels).sum().item()\n",
        "                \n",
        "            # 將當前 batch 記錄下來\n",
        "            if predictions is None:\n",
        "                predictions = pred\n",
        "            else:\n",
        "                predictions = torch.cat((predictions, pred))\n",
        "    \n",
        "    if compute_acc:\n",
        "        acc = correct / total\n",
        "        return predictions, acc\n",
        "    return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oePWzrGKgw54",
        "colab_type": "code",
        "outputId": "3553477e-193b-411b-b1da-13d491e63212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# 讓模型跑在 GPU 上並取得訓練集的分類準確率\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "model = model.to(device)\n",
        "pred, acc = get_predictions(model, trainloader, compute_acc=True)\n",
        "print(\"classification acc:\", acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cuda:0\n",
            "classification acc: 0.031825795644891124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGe1Dv8ogw-C",
        "colab_type": "code",
        "outputId": "44997636-bb26-4377-db84-ae0ed968e2b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "model = model.to(device)\n",
        "\n",
        "# 使用 Adam Optim 更新整個分類模型的參數\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "EPOCHS = 20\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, EPOCHS))\n",
        "    print('Training...')\n",
        "\n",
        "    # 訓練模式\n",
        "    model.train()\n",
        "\n",
        "    for data in trainloader: # trainloader is an iterator over each batch\n",
        "        \n",
        "        tokens_tensors, segments_tensors, \\\n",
        "        masks_tensors, labels = [t.to(device) for t in data]\n",
        "\n",
        "        # 將參數梯度歸零\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(input_ids=tokens_tensors, \n",
        "                        token_type_ids=segments_tensors, \n",
        "                        attention_mask=masks_tensors, \n",
        "                        labels=labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        # backward\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # 紀錄當前 batch loss\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    # 計算分類準確率\n",
        "    logit, acc = get_predictions(model, trainloader, compute_acc=True)\n",
        "\n",
        "    print('loss: %.3f, acc: %.3f' %\n",
        "          (running_loss, acc))    \n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for data in valloader:\n",
        "        \n",
        "        tokens_tensors, segments_tensors, \\\n",
        "        masks_tensors, labels = [t.to(device) for t in data]\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            outputs = model(input_ids=tokens_tensors, \n",
        "                        token_type_ids=segments_tensors, \n",
        "                        attention_mask=masks_tensors, \n",
        "                        labels=labels)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "\n",
        "    _, acc = get_predictions(model, valloader, compute_acc=True)\n",
        "        # Move logits and labels to CPU\n",
        "        #logits = logits.detach().cpu().numpy()\n",
        "        #label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        #tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        #eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        #nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cuda:0\n",
            "\n",
            "======== Epoch 1 / 50 ========\n",
            "Training...\n",
            "loss: 109.372, acc: 0.663\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.68\n",
            "\n",
            "======== Epoch 2 / 50 ========\n",
            "Training...\n",
            "loss: 61.972, acc: 0.771\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.77\n",
            "\n",
            "======== Epoch 3 / 50 ========\n",
            "Training...\n",
            "loss: 43.051, acc: 0.832\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "\n",
            "======== Epoch 4 / 50 ========\n",
            "Training...\n",
            "loss: 31.905, acc: 0.868\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "\n",
            "======== Epoch 5 / 50 ========\n",
            "Training...\n",
            "loss: 24.140, acc: 0.917\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "\n",
            "======== Epoch 6 / 50 ========\n",
            "Training...\n",
            "loss: 18.093, acc: 0.942\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.90\n",
            "\n",
            "======== Epoch 7 / 50 ========\n",
            "Training...\n",
            "loss: 13.495, acc: 0.957\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.92\n",
            "\n",
            "======== Epoch 8 / 50 ========\n",
            "Training...\n",
            "loss: 10.479, acc: 0.959\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.91\n",
            "\n",
            "======== Epoch 9 / 50 ========\n",
            "Training...\n",
            "loss: 8.367, acc: 0.979\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.92\n",
            "\n",
            "======== Epoch 10 / 50 ========\n",
            "Training...\n",
            "loss: 6.362, acc: 0.990\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.92\n",
            "\n",
            "======== Epoch 11 / 50 ========\n",
            "Training...\n",
            "loss: 4.794, acc: 0.991\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.93\n",
            "\n",
            "======== Epoch 12 / 50 ========\n",
            "Training...\n",
            "loss: 3.679, acc: 0.992\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.93\n",
            "\n",
            "======== Epoch 13 / 50 ========\n",
            "Training...\n",
            "loss: 3.117, acc: 0.994\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "\n",
            "======== Epoch 14 / 50 ========\n",
            "Training...\n",
            "loss: 2.511, acc: 0.996\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.93\n",
            "\n",
            "======== Epoch 15 / 50 ========\n",
            "Training...\n",
            "loss: 2.154, acc: 0.997\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.93\n",
            "\n",
            "======== Epoch 16 / 50 ========\n",
            "Training...\n",
            "loss: 1.678, acc: 0.998\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "\n",
            "======== Epoch 17 / 50 ========\n",
            "Training...\n",
            "loss: 1.499, acc: 0.997\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.93\n",
            "\n",
            "======== Epoch 18 / 50 ========\n",
            "Training...\n",
            "loss: 1.202, acc: 0.997\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "\n",
            "======== Epoch 19 / 50 ========\n",
            "Training...\n",
            "loss: 1.014, acc: 0.998\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "\n",
            "======== Epoch 20 / 50 ========\n",
            "Training...\n",
            "loss: 0.912, acc: 0.997\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "\n",
            "======== Epoch 21 / 50 ========\n",
            "Training...\n",
            "loss: 1.016, acc: 0.998\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.93\n",
            "\n",
            "======== Epoch 22 / 50 ========\n",
            "Training...\n",
            "loss: 1.206, acc: 0.998\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.93\n",
            "\n",
            "======== Epoch 23 / 50 ========\n",
            "Training...\n",
            "loss: 0.881, acc: 0.998\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "\n",
            "======== Epoch 24 / 50 ========\n",
            "Training...\n",
            "loss: 0.809, acc: 0.998\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "\n",
            "======== Epoch 25 / 50 ========\n",
            "Training...\n",
            "loss: 0.850, acc: 0.998\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "\n",
            "======== Epoch 26 / 50 ========\n",
            "Training...\n",
            "loss: 0.740, acc: 0.998\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.93\n",
            "\n",
            "======== Epoch 27 / 50 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-077ba5852c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Clip the norm of the gradients to 1.0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2KH1yPNkU9z",
        "colab_type": "text"
      },
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jY7t0cAkWkQ",
        "colab_type": "code",
        "outputId": "792d9a42-031d-474c-a3bb-70ba80b014fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import os\n",
        "output_dir = os.path.join(\"0303_intent_newclass\", \"model23\", \"25e70%labeled\")\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to 0303_intent_newclass/model23/25e70%labeled\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('0303_intent_newclass/model23/25e70%labeled/vocab.txt',\n",
              " '0303_intent_newclass/model23/25e70%labeled/special_tokens_map.json',\n",
              " '0303_intent_newclass/model23/25e70%labeled/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUNMQzzmkQks",
        "colab_type": "text"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCM_tmnrgxGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 建立測試集。這邊我們可以用跟訓練時不同的 batch_size，看你 GPU 多大\n",
        "#testset = OnlineQueryDataset(\"test\", tokenizer=tokenizer)\n",
        "testloader = DataLoader(testset, batch_size=32, \n",
        "                        collate_fn=create_mini_batch)\n",
        "\n",
        "# 用分類模型預測測試集\n",
        "predictions= get_predictions(model, testloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNmHwnBcltYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(label, pred):\n",
        "    return (label == pred).sum().item()/len(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcsmaLhpmGXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_label = torch.cuda.FloatTensor(testset.df['index'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZmmKS8mmH8q",
        "colab_type": "code",
        "outputId": "450e2778-ea3b-4722-fd3b-a9bde282dcc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Testset accuracy: %f\" % accuracy(test_label, predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testset accuracy: 0.930709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KvQImfdok6Z",
        "colab_type": "text"
      },
      "source": [
        "若只用能依照ivr分類邏輯來分類的資料的話（共15類），可達test accuracy 98% <br>\n",
        "加入其他無法確切分類後的資料，並再將之概略分為8類後，test accuracy下降至93%左右\n"
      ]
    }
  ]
}